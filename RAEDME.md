# ğŸ›ï¸ Similar Product Recommendation System

**CLIP â€¢ FAISS â€¢ MMR â€¢ FastAPI â€¢ Streamlit**

An end-to-end **production-style similarity recommendation system** that retrieves visually and semantically similar products using deep embeddings, approximate nearest neighbor search, and diversity-aware re-ranking.

This project demonstrates **real-world ML system design**, not just model training.

---

## ğŸ” Problem Statement

Given a product (image + metadata), recommend **similar products** that are:

* Visually and semantically relevant
* Fast to retrieve at scale
* Explainable to stakeholders
* Tunable for **exploration vs business control**

---

## ğŸš€ Key Features

* **CLIP image embeddings** for semantic similarity
* **Hybrid embeddings** (image + text + category signal)
* **FAISS** for fast approximate nearest neighbor (ANN) retrieval
* **MMR (Maximal Marginal Relevance)** for diversity control
* **Soft category similarity** (semantic) + **hard category match** (business)
* **FastAPI** backend for production-style serving
* **Streamlit UI** as a thin client (no ML logic in UI)
* Clear evaluation and explainability

---

## ğŸ§  System Architecture

```
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   Product Dataset   â”‚
                 â”‚ (Images + Metadata) â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Data Ingestion &   â”‚
                 â”‚  Preprocessing      â”‚
                 â”‚ (validation, resize)â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚     Embedding Generation          â”‚
          â”‚  - CLIP Image Embeddings          â”‚
          â”‚  - CLIP Text Embeddings           â”‚
          â”‚  - Hybrid Embeddings              â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   FAISS Index       â”‚
                 â”‚ (ANN Recall Layer)  â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   MMR Re-Ranking    â”‚
                 â”‚ (Relevance vs       â”‚
                 â”‚  Diversity Control) â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Semantic + Businessâ”‚
                 â”‚  Re-Ranking         â”‚
                 â”‚ (category signals)  â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚        FastAPI           â”‚
              â”‚   /recommend endpoint    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚       Streamlit UI       â”‚
              â”‚  (Visualization +        â”‚
              â”‚   Explainability)        â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Dataset

**Source:** Kaggle Fashion Product Images Dataset

**Contents:**

* ~44,000 fashion product images
* Metadata fields:

  * `product_id`
  * `articleType` (category)
  * `baseColour`
  * `season`
  * `usage`
  * `productDisplayName`

**Why this dataset?**

* Realistic noise (missing images, inconsistent labels)
* Requires ingestion validation
* Forces robust system design (not toy-clean data)

---

## ğŸ“Š Recommendation Models

### 1ï¸âƒ£ CLIP (Exploratory)

* Uses CLIP image embeddings
* Optimized for **semantic similarity**
* Allows cross-category recommendations
* Higher diversity, lower business control

### 2ï¸âƒ£ Hybrid (Business-Controlled)

* Combines:

  * Image similarity
  * Text/category semantics
* Higher category consistency
* Lower diversity (intentional)

---

## ğŸ¯ Diversity Control (MMR)

We apply **Maximal Marginal Relevance (MMR)** after FAISS recall:

[
MMR(d) = \lambda \cdot sim(query, d) - (1 - \lambda) \cdot \max sim(d, selected)
]

* `Î» â‰ˆ 0.9` â†’ highly relevant, less diverse
* `Î» â‰ˆ 0.5` â†’ balanced
* `Î» â‰ˆ 0.1` â†’ exploratory, diverse

Exposed directly in the UI.

---

## ğŸ§  Explainability

Each recommendation includes:

* **ANN similarity score**
* **Soft category similarity** (semantic closeness via CLIP text embeddings)
* **Hard category match** (exact label equality)

This avoids misleading metrics like â€œPrecision@5 = 0.0â€ for valid semantic results.

---


## ğŸ”¬ Model Comparison & Evaluation

This project evaluates **multiple embedding strategies** to understand trade-offs between relevance, diversity, latency, and business control.

The goal is **not** to find a single â€œbestâ€ model, but to understand **when each model should be used**.

---

## ğŸ¤– Evaluated Models

### 1ï¸âƒ£ ResNet (Baseline)

**Description**

* CNN trained for image classification
* Used as a feature extractor (final pooling layer)

**Why included**

* Strong visual baseline
* Common in legacy vision systems
* Helps quantify gains from modern multimodal models

**Strengths**

* Good color and texture matching
* Stable and predictable behavior

**Limitations**

* No semantic understanding
* Fails on style, intent, or abstract similarity

---

### 2ï¸âƒ£ EfficientNet

**Description**

* Parameter-efficient CNN with compound scaling
* Produces stronger visual embeddings than ResNet

**Why included**

* Better accuracy-latency trade-off
* Common upgrade path in production vision systems

**Strengths**

* Improved visual discrimination
* Lower latency than ResNet

**Limitations**

* Still purely visual
* Cannot reason about semantics or category intent

---

### 3ï¸âƒ£ CLIP (Image-Only)

**Description**

* Visionâ€“language model trained on imageâ€“text pairs
* Image embeddings capture **semantic meaning**

**Why included**

* Represents modern retrieval systems
* Enables cross-category and style-based similarity

**Strengths**

* Strong semantic similarity
* Handles style, intent, and abstract concepts
* Very fast ANN retrieval

**Limitations**

* Ignores business taxonomy
* Can recommend â€œrelatedâ€ but different categories

---

### 4ï¸âƒ£ Hybrid (CLIP + Category Signal)

**Description**

* Combines CLIP embeddings with category semantics
* Adds business awareness without retraining CLIP

**Why included**

* Mirrors real-world recommender constraints
* Balances exploration and control

**Strengths**

* High relevance
* Strong category consistency
* Predictable for merchandising

**Limitations**

* Reduced diversity
* Less exploratory by design

---

## ğŸ“Š Evaluation Metrics

We evaluate models across **relevance, diversity, and system performance**.

### ğŸ”¹ Precision@5 (Category Proxy)

* Measures how many recommended items share the same category
* Useful as a **business proxy**, not absolute relevance

âš ï¸ Limitation:
Semantic models (CLIP) may score low despite valid recommendations.

---

### ğŸ”¹ Category Consistency

* Fraction of recommendations matching the query category
* Indicates catalog alignment and business control

---

### ğŸ”¹ ILD@5 (Intra-List Diversity)

* Measures average dissimilarity among recommended items
* Higher = more diverse results

---

### ğŸ”¹ Category Spread@5

* Number of unique categories in the recommendation list
* Captures exploration across catalog structure

---

### ğŸ”¹ Avg Query Latency (ms)

* End-to-end retrieval latency
* Important for real-time systems

---

## ğŸ“ˆ Final Evaluation Results

| Model        | Precision@5 | Category Consistency | ILD@5 | Category Spread@5 | Avg Latency (ms) |
| ------------ | ----------- | -------------------- | ----- | ----------------- | ---------------- |
| ResNet       | 0.764       | 0.820                | 0.068 | 0.331             | 31.22            |
| EfficientNet | 0.808       | 0.860                | 0.194 | 0.298             | 19.41            |
| CLIP         | 0.816       | 0.872                | 0.061 | 0.298             | 7.82             |
| **Hybrid**   | **0.961**   | **0.988**            | 0.069 | 0.227             | **7.80**         |

---

## ğŸ§  How to Interpret These Results (Important)

### Why CLIP can have lower Precision@5 but still be correct

* CLIP optimizes **semantic similarity**, not taxonomy
* Recommending â€œSunglassesâ€ for â€œWatchesâ€ can be valid
* Hard category metrics underestimate semantic relevance

â¡ï¸ This is why we expose **soft category similarity**.

---

### Why Hybrid scores highest on Precision@5

* Category signal is explicitly injected
* This is intentional and business-driven
* Not â€œbetter MLâ€ â€” **better alignment with constraints**

---

### Why ILD is lower for Hybrid

* Business control reduces exploration
* This is a **trade-off**, not a failure

---

### Why MMR is critical

* FAISS recall returns near-duplicates
* MMR explicitly balances:

  * relevance
  * redundancy
  * diversity

This allows **runtime tuning** without retraining.

---

## ğŸ¯ Model Selection Guidelines

| Use Case                            | Recommended Model |
| ----------------------------------- | ----------------- |
| Visual similarity only              | EfficientNet      |
| Style / semantic discovery          | CLIP              |
| Business-controlled recommendations | Hybrid            |
| Exploration vs control tuning       | Any + MMR         |

---

## ğŸ§  Key Insight

There is **no universally best model**.

A good recommender system:

* exposes trade-offs
* explains behavior
* adapts to business goals

---

## ğŸ—ï¸ Project Structure
```
similar-product-recommendation/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Original dataset (images + CSV)
â”‚   â””â”€â”€ processed/               # Validated images + cleaned metadata
â”‚
â”œâ”€â”€ artifacts/                   # Generated model artifacts
â”‚   â”œâ”€â”€ resnet/                  # ResNet embeddings + product IDs
â”‚   â”œâ”€â”€ efficientnet/            # EfficientNet embeddings + product IDs
â”‚   â”œâ”€â”€ clip_image/              # CLIP image embeddings
â”‚   â”œâ”€â”€ clip_text/               # CLIP text embeddings
â”‚   â””â”€â”€ hybrid/                  # Hybrid embeddings (image + category)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/               # Data ingestion & validation
â”‚   â”‚   â”œâ”€â”€ kaggle_ingest.py
â”‚   â”‚   â”œâ”€â”€ validate.py
â”‚   â”‚   â””â”€â”€ normalize.py
â”‚   â”‚
â”‚   â”œâ”€â”€ modeling/                # Embedding generation
â”‚   â”‚   â”œâ”€â”€ resnet/
â”‚   â”‚   â”œâ”€â”€ efficientnet/
â”‚   â”‚   â”œâ”€â”€ clip_image/
â”‚   â”‚   â”œâ”€â”€ clip_text/
â”‚   â”‚   â””â”€â”€ hybrid/
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/              # Offline evaluation & metrics
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â”œâ”€â”€ diversity.py
â”‚   â”‚   â””â”€â”€ evaluate_models.py
â”‚   â”‚
â”‚   â”œâ”€â”€ indexing/                # Index construction (offline)
â”‚   â”‚   â””â”€â”€ build_faiss_index.py
â”‚   â”‚
â”‚   â””â”€â”€ api/                     # Online serving layer
â”‚       â”œâ”€â”€ main.py              # FastAPI application
â”‚       â”œâ”€â”€ faiss_index.py       # FAISS wrapper + ID mapping
â”‚       â”œâ”€â”€ rerank.py            # Semantic + business re-ranking
â”‚       â”œâ”€â”€ mmr.py               # Diversity-aware re-ranking (MMR)
â”‚       â””â”€â”€ schemas.py           # API request/response models
â”‚
â”œâ”€â”€ streamlit_app.py             # Streamlit UI (thin client)
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ noteook                      # Experimental notebook
â”œâ”€â”€ tests/                       # Optional: unit / integration tests
â”‚   â””â”€â”€ test_api.py
â”‚
â””â”€â”€ README.md                    # Project documentation
```

---

## â–¶ï¸ How to Run (End-to-End)

### 1ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Generate embeddings (one-time)

```bash
python src/ingestion/kaggle_ingest.py
python src/modeling/clip_image/batch_embed.py
python src/modeling/clip_text/batch_embed.py
python src/modeling/hybrid/batch_embed.py
```

### 3ï¸âƒ£ Start FastAPI backend

```bash
uvicorn src.api.main:app --reload
```

Verify:

```
http://127.0.0.1:8000/docs
```

### 4ï¸âƒ£ Start Streamlit UI

```bash
streamlit run streamlit_app.py
```

Open:

```
http://localhost:8501
```

---

## ğŸ§ª API Example

```http
GET /recommend?product_id=15970&model=clip&top_k=5&lambda_diversity=0.7
```

Returns:

```json
{
  "query_product_id": "15970",
  "model": "clip",
  "top_k": 5,
  "results": [
    {
      "product_id": "39386",
      "score": 0.812,
      "ann_score": 0.94,
      "category_similarity": 0.67,
      "category_match": false
    }
  ]
}
```

---

## ğŸ¤ Summary

> â€œDesigned a two-stage recommender system: FAISS for fast recall, followed by MMR and semantic re-ranking for controllable diversity and explainability. The UI is a thin client consuming a FastAPI service, mirroring production ML systems.â€

---

## ğŸš§ Future Improvements

* Online A/B testing
* User interaction feedback loop
* Learned re-ranking model
* Caching layer (Redis)
* Cloud deployment (ECS / GKE)

---

## âœ… Key Takeaway

This project is not about â€œtraining a modelâ€.

It demonstrates:

* **System design**
* **Trade-off reasoning**
* **Production ML thinking**
* **Explainability over blind metrics**

